#### La distribución normal: medir una longitud de 5m con un aparato cuyo margen de error es 25cm

Todo experimento consiste en realizar una actividad y, en el curso de ella, medir "algo". Si repetimos el experimento muchas veces (o si lo realizamos sobre muchos individuos) vamos obteniendo una muestra de resultados. A este número de veces que se repite el experimento se le llama "tamaño muestral", que es nuestro caso es `r my_tamamu`.

En este caso:
    
    + Actividad: Medir una barra cuya longitud sabemos que es 5 metros con un aparato cuya precisión es de 25 cm, es decir, 0.25 metros.  
+ Medida: la implícita en la actividad.
+ Repeticiones del experimento:`r my_tamamu` veces.

La función "rnorm" realiza el experimento por nosotros. Sus parámetros son:
    
    + mean: la longitud verdadera de la barra, que es 5
+ sd: el margen de error del aparato de medida, que es 0.25
+ n: número de veces que repetimos el proceso de medición, que es `r my_tamamu`.

```{r}
my_n = my_tamamu
my_mean = 5
my_sd = 0.25
muestra <- round( rnorm(n=my_n, mean=my_mean, sd=my_sd) ,2)
```

La muestra de resultados:
    ```{r}
head(muestra, 30)
ggplot() + 
    geom_histogram(aes(x = muestra, y = ..density..),
                   color = "white", 
                   fill = "orange", 
                   binwidth = 0.01) +
    labs(title = "Histograma")
```

Podemos recoger en una tabla cuantas veces ha salido cada resultado:
    ```{r}
df <- data.frame(medidas = muestra) %>% 
    group_by(medidas) %>% 
    summarise(veces = n()) %>%
    arrange(-veces)
df
```

```{r message = FALSE, warning = FALSE, echo = FALSE}
frecuencia <- round(df$veces[1] / my_n,4)
porcentaje = frecuencia * 100
```

Vemos que el resultado más repetido es `r df$medidas[1]`, que ha ocurrido `r df$veces[1]` veces. Como el máximo de veces que podía repetirse era `r my_n`, esto supone una proporción de `r round(df$veces[1] / my_n,4)` o un porcentaje del `r round(df$veces[1] / my_n,4) * 100`%. A esta proporción se le llama **frecuencia** del resultado `r df$medidas[1]`.

Podemos recoger en una tabla las frecuencias de todas los resultados:
    ```{r}
distri_nor <- mutate(df, frecuencia = round(veces / my_n,4))
distri_nor <- select(distri_nor, medidas, frecuencia)
distri_nor
```


#### Abstracción

Cualquier experimento que se haga para medir "algo" acabará siempre como el anterior, es decir, con una muestra de resultados obtenidos y una tabla de resultados y frecuencias.

Si la tabla de resultados y frecuencias coincide con la que acabamos de obtener (mismos resultados y misma frecuencia para cada resultado) diremos que el experimento indica que _lo que se está midiendo_ sigue una distribución  normal de media 5 y desviación típica 0.25.

Por ejemplo, si medimos los pesos de niños de 3 meses de edad que han pasado por una clínica pediátrica, podría ser que saliera la tabla anterior (en particular, el peso más repetido sería 5 kg). En ese caso diríamos que los pesos de los niños de 3 meses de edad que han pasado por esa clínica pediátrica siguen una distribución normal de media 5 kg y desviación típica 0.25 kg.

Obviamente, podemos decir que las medidas de un barra de 5 metros con una aparato cuya precisión es de 0.25 metros siguen una distribución normal de media 5 metros y desviación típica 0.25 metros.

Otros ejemplos serían:
    
    + Cualquier medida de características naturales (altura, coeficiente de inteligencia, tensión arterial...) suele seguir una distribución normal.

#### La distribución de Poisson: esperar 2 horas un autobús que suele pasar 4 veces cada hora

Todo experimento consiste en realizar una actividad y, en el curso de ella, medir "algo". Si repetimos el experimento muchas veces (o si lo realizamos sobre muchos individuos) vamos obteniendo una muestra de resultados. A este número de veces que se repite el experimento se le llama "tamaño muestral", que es nuestro caso es `r my_tamamu`.

En este caso:
    
    + Actividad: Esperar 2 horas en una parada de un autobús que tiene una frecuencia habitual de 4 autobuses por hora.
+ Medida: contar cuántos autobuses realmente pasan.  
+ Repeticiones del experimento: `r my_tamamu` veces.

La función "rpois" realiza el experimento por nosotros. Sus parámetros son:
    
    + $\lambda$: resultado de multiplicar la frecuencia horaria habitual por el número de horas que vamos a esperar, es decir: 4 * 2 = 8.  
+ n: número de veces que vamos a esperar 2 horas contando autobuses, que es `r my_tamamu`.  

```{r}
my_ = my_tamamu
my_lambda = 4 * 2
muestra <- rpois(n=my_n, lambda=my_lambda)
```

La muestra de resultados es:
    ```{r}
head(muestra, 30)
ggplot() + 
    geom_histogram(aes(x = muestra, y = ..density..),
                   color = "white", 
                   fill = "orange", 
                   binwidth = 1) +
    labs(title = "Histograma")
```

Podemos recoger en una tabla cuantas veces ha salido cada resultado:
    ```{r}
df <- data.frame(nro_autobuses = muestra) %>% 
    group_by(nro_autobuses) %>% 
    summarise(veces = n()) %>%
    arrange(-veces)
df
```

```{r message = FALSE, warning = FALSE, echo = FALSE}
frecuencia <- round(df$veces[1] / my_n,4)
porcentaje = frecuencia * 100
```

Vemos que el resultado más repetido es `r df$nro_autobuses[1]`, que ha ocurrido `r df$veces[1]` veces. Como el máximo de veces que podía repetirse era `r my_n`, esto supone una proporción de `r round(df$veces[1] / my_n,4)` o un porcentaje del `r round(df$veces[1] / my_n,4) * 100`%. A esta proporción se le llama **frecuencia** del resultado `r df$nro_autobuses[1]`.

Podemos recoger en una tabla las frecuencias de todos los resultados:
    ```{r}
distri_poi <- mutate(df, frecuencia = round(veces / my_n,4))
distri_poi <- select(distri_poi, nro_autobuses, frecuencia)
distri_poi
```

#### Abstracción

Cualquier experimento que se haga para medir "algo" acabará siempre como el anterior, es decir, con una muestra de resultados obtenidos y una tabla de resultados y frecuencias.

Si la tabla de resultados y frecuencias coincide con la que acabamos de obtener (mismos resultados y misma frecuencia para cada resultado) diremos que el experimento indica que _lo que se está midiendo_ sigue una distribución de Poisson de parámetro $\lambda$ = 4*2 = 8.

Por ejemplo, si medimos la edad de las personas ingresadas en un hospital podría ser que saliera la tabla anterior (los niños de 8 años serían, en particular, los más habituales). Diríamos que la edad de las personas internadas en ese hospital sigue una distribución de Poisson de parámetro $\lambda$ = 4*2 = 8.

Obviamente, podemos decir que el recuento durante 2 horas de los autobuses que llegan a una parada cuya frecuencia habitual es de 4 autobuses por hora sigue una distribución de Poisson de parámetro $\lambda$ = 4*2 = 8.

Otros ejemplos serían:
    
    + El número de usuarios que accederán a una web de 9:00 a 17:00, si lo habitual es 15 usuarios por hora, sigue una distribución de Poisson de parámetro $\lambda$ = 15 * 8 = 120.  
+ El número de errores que cometerá una mecanógrafa en las próximas 15 páginas que escriba, si habitualmente comete 2 errores cada 5 páginas, sigue una distribución de Poisson de parámetro $\lambda$ = 2/5 * 15 = 6.
+ El número de camisetas que vende una tienda, si lo habitual es 12 camisetas cada día, sigue una distribución de Poisson de parámetro $\lambda$ = 15*1 = 15.


## La ley de los grandes números

Lo que se puede ver en los experimentos anteriores es lo que dice la **Ley de los grandes números**: _a partir de un tamaño muestral, posiblemente muy grande, es decir, a partir de cierto número de repeticiones del experimento, las tablas de resultados se estabilizan; mismos resultados y mismas frecuencias_.

En efecto, rehaciendo este documento una y otra vez se ve que los resultados son prácticamente los mismos y las frecuencias coinciden hasta el tercer o cuarto decimal, apróximadamente.

```{r}
distri_bin
distri_nor
distri_poi
```

Esto se interpreta como que existen unos _resultados teóricos_ del experimento y una _frecuencia teórica_ para cada resultado. R los tiene almacenados en funciones. Por desgracia, estas funciones lo que nos dan es la frecuencia "acumulada" y es necesario algo de trabajo para extraer la frecuencia "a secas".


#### Frecuencias acumuladas y percentiles de la distribución binomial (funciones pbinom y qbinom)

La función **pbinom** nos da la _frecuencia acumulada_, es decir, la suma de las frecuencias de todos los valores hasta llegar al que le indiquemos (incluido). Por ejemplo, para nuestra binomial de tamaño 90 y probabilidad 1/6, podemos preguntarnos cuánto suman las frecuencias hasta llegar al valor más repetido (el 15):
    ```{r}
pbinom(15, size=90, prob=1/6)
```

La frecuencia "a secas" del valor 15 se obtendría restando a su frecuencia acumulada la del valor anterior:
    ```{r}
pbinom(15, size=90, prob=1/6) - pbinom(15 - 1, size=90, prob=1/6)
```

Es fácil construir una función **fbinom** que automatice esto:
    ```{r}
fbinom <- function(valor, size, prob) {
    pbinom(valor, size=size, prob=prob) - 
        pbinom(valor - 1, size=size, prob=prob)
}

fbinom(15, size=90, prob=1/6)
```

Veamos como suben las frecuencias acumuladas hasta llegar al valor más repetido (15):
    ```{r}
valores <- seq(12,15)
frecuencias_acumuladas <- pbinom(valores, size=90, prob=1/6)
binomial <- data.frame(valores, frecuencias_acumuladas)
binomial
```

En el valor 15 superamos, entonces, por primera vez la frecuencia acumulada del 50% (frecuencia acumulada, 0.5). Esta misma información (en qué valor igualamos o superamos la frecuencia acumulada 0.5) nos la da directamente la función **qbinom**. A este valor se le llama _percentil 50_:
    ```{r}
percentil_50 <- qbinom(0.5, size=90, prob=1/6)
percentil_50
```

```{r message = FALSE, warning = FALSE, echo = FALSE}
cifras <- 5
frecuencia_min <- 10^(-cifras)
frecuencia_max <- 1-10^(-cifras)
```
Por construcción, la suma de todas las frecuencias tiene que ser 1. Entonces, una forma de saber en qué valor empieza a acumularse algo de frecuencia y en qué valor ya está casi toda acumulada, es preguntar a qbinom en qué valor igualamos o superamos las frecuencias acumuladas `r frecuencia_min` y `r frecuencia_max`. Estos valores se llaman, respectivamente, _percentil mínimo_ y _percentil máximo_:
    ```{r}
percentil_min <- qbinom(frecuencia_min, size=90, prob=1/6)
percentil_min
percentil_max <- qbinom(frecuencia_max, size=90, prob=1/6)
percentil_max
```

Sabiendo el rango de valores que manejamos, podemos construir una tabla de valores y frecuencias práctica. **A esta tabla es a lo que se llama, en la práctica, la distribución binomial de tamaño 90 y probabilidad 1/6**.
```{r}
valores <- round(seq(percentil_min, percentil_max, by=1) ,0)
frecuencias <- fbinom(valores, size=90, prob=1/6)
frecuencias_acumuladas <- pbinom(valores, size=90, prob=1/6)
frecuencias <- round(frecuencias, cifras)
frecuencias_acumuladas <- round(frecuencias_acumuladas, cifras)
distri_bin <- data.frame(valores, frecuencias, frecuencias_acumuladas)
```

```{r}
curva_bin <- ggplot(data = distri_bin, 
                    aes(x=valores, y=frecuencias)) + 
    geom_line(color = "blue", size=1) + 
    labs(title = "Distribución binomial de tamaño 90 y probabilidad 1/6")
curva_bin
```

Finalmente, una muestra "perfecta" de resultados que daría justo las frecuencias teóricas, se puede construir:
    ```{r}
muestra_bin <- rep(distri_bin$valores, 
                   round(distri_bin$frecuencias * my_tamamu,0))

head(muestra_bin, 200)

ggplot() + 
    geom_histogram(aes(x = muestra_bin, y = ..density..),
                   color = "white", 
                   fill = "orange", 
                   binwidth = 01) +
    labs(title = "Histograma")
```

#### Frecuencias acumuladas y percentiles de la distribución normal (funciones pnorm y qnorm)

La función **pnorm** nos da la _frecuencia acumulada_, es decir, la suma de las frecuencias de todos los valores hasta llegar al que le indiquemos (incluido). Por ejemplo, para nuestra normal de media 5 y desviación típica 0.25, podemos preguntarnos cuánto suman las frecuencias hasta llegar al valor más repetido (el 5):
    ```{r}
pnorm(5, mean=5, sd=0.25)
```

La frecuencia "a secas" del valor 5 se obtendría restando a su 
frecuencia acumulada la del valor anterior. En la distribución normal, el concepto de "valor anterior" depende de la precisión con que medimos los valores. En nuestro caso, ha sido hasta el centímetro:
    ```{r}
pnorm(5, mean=5, sd=0.25)- pnorm(5 - 0.01, mean=5, sd=0.25)
```

Es fácil construir una función **fnorm** que automatice esto:
    ```{r}
fnorm <- function(valor, mean, sd) {
    pnorm(valor, mean=mean, sd=sd) - 
        pnorm(valor - 0.01, mean=mean, sd=sd)
}

fnorm(5, mean=5, sd=0.25)
```

Veamos como suben las frecuencias acumuladas hasta llegar al valor 
más repetido (5):
    
    ```{r}
valores <- seq(4,5, by=0.25)
frecuencias_acumuladas <- round( pnorm(valores, mean=5, sd=0.25) ,4)
normal <- data.frame(valores, frecuencias_acumuladas)
normal
```
En el valor 5 llegamos, entonces, por primera vez a la frecuencia acumulada del 50% (frecuencia acumulada, 0.5). Esta misma información (en qué valor igualamos o superamos la frecuencia acumulada 0.5) nos la da directamente la función **qnorm**. A este valor se le llama _percentil 50_:
    ```{r}
percentil_50 <- qnorm(0.5, mean=5, sd=0.25)
percentil_50
```

```{r message = FALSE, warning = FALSE, echo = FALSE}
frecuencia_min <- 0.00001
frecuencia_max <- 0.99999
```
Por construcción, la suma de todas las frecuencias tiene que ser 1. Entonces, una forma de saber en qué valor empieza a acumularse algo de frecuencia y en qué valor ya está casi toda acumulada, es preguntar a qnorm en qué valor igualamos o superamos las frecuencias acumuladas `r frecuencia_min` y `r frecuencia_max`. Estos valores se llaman, respectivamente, _percentil mínimo_ y _percentil máximo_:
    ```{r}
percentil_min <- qnorm(frecuencia_min, mean=5, sd=0.25)
percentil_min
percentil_max <- qnorm(frecuencia_max, mean=5, sd=0.25)
percentil_max
```

Sabiendo el rango de valores que manejamos, podemos construir una tabla de valores y frecuencias práctica. **A esta tabla es a lo que se llama, en la práctica, la distribución normal de media 5 y desviación típica 0.25**.
```{r}
valores <- round(seq(percentil_min,percentil_max, by=0.01), 2)
frecuencias <- fnorm(valores, mean=5, sd=0.25)
frecuencias_acumuladas <- pnorm(valores, mean=5, sd=0.25)
frecuencias <- round(frecuencias, cifras)
frecuencias_acumuladas <- round(frecuencias_acumuladas, cifras)
distri_nor <- data.frame(valores, frecuencias, frecuencias_acumuladas)
```

```{r}
curva_nor <- ggplot(data = distri_nor, 
                    aes(x=valores, y=frecuencias)) + 
    geom_line(color = "blue", size=1) + 
    labs(title = "Distribución normal de media 5 y desviación típica 0.25")
curva_nor
```

Finalmente, una muestra "perfecta" de resultados que daría justo las frecuencias teóricas, se puede construir:
    ```{r}
muestra_nor <- rep(distri_nor$valores, 
                   round(distri_nor$frecuencias * my_tamamu, 0))

head(muestra_nor, 200)

ggplot() + 
    geom_histogram(aes(x = muestra_nor, y = ..density..),
                   color = "white", 
                   fill = "orange", 
                   binwidth = 0.01) +
    labs(title = "Histograma")
```

#### Frecuencias acumuladas y percentiles de la distribución de Poisson (funciones ppois y qpois)

La función **ppois** nos da la _frecuencia acumulada_, es decir, la suma de las frecuencias de todos los valores hasta llegar al que le indiquemos (incluido). Por ejemplo, para nuestra poisson de $\lambda = 4*2 = 8$, podemos preguntarnos cuánto suman las frecuencias hasta llegar al valor más repetido (el 8):
    ```{r}
ppois(8, lambda=4*2)
```

La frecuencia "a secas" del valor 8 se obtendría restando a su 
frecuencia acumulada la del valor anterior:
    ```{r}
ppois(8, lambda=4*2) - ppois(8 - 1, lambda=4*2)
```

Es fácil construir una función **fpois** que automatice esto:
    ```{r}
fpois <- function(valor, lambda) {
    ppois(valor, lambda = lambda) - 
        ppois(valor - 1, lambda = lambda)
}

fpois(8, lambda=4*2)
```

Veamos como suben las frecuencias acumuladas hasta llegar al valor 
más repetido (8):
    ```{r}
valores <- seq(4,8)
frecuencias_acumuladas <- round( ppois(valores, lambda=4*2) ,4)
poisson <- data.frame(valores, frecuencias_acumuladas)
poisson
```
En el valor 8 superamos, entonces, por primera vez la frecuencia acumulada del 50% (frecuencia acumulada, 0.5). Esta misma información (en qué valor igualamos o superamos la frecuencia acumulada 0.5) nos la da directamente la función **qpois**. A este valor se le llama _percentil 50_:
    ```{r}
percentil_50 <- qpois(0.5, lambda=4*2)
percentil_50
```

```{r message = FALSE, warning = FALSE, echo = FALSE}
frecuencia_min <- 0.00001
frecuencia_max <- 0.99999
```
Por construcción, la suma de todas las frecuencias tiene que ser 1. Entonces, una forma de saber en qué valor empieza a acumularse algo de frecuencia y en qué valor ya está casi toda acumulada, es preguntar a qpois en qué valor igualamos o superamos las frecuencias acumuladas `r frecuencia_min` y `r frecuencia_max`. Estos valores se llaman, respectivamente, _percentil mínimo_ y _percentil máximo_:
    ```{r}
percentil_min <- qpois(frecuencia_min, lambda=4*2)
percentil_min
percentil_max <- qpois(frecuencia_max, lambda=4*2)
percentil_max
```

Sabiendo el rango de valores que manejamos, podemos construir una tabla de valores y frecuencias práctica. **A esta tabla es a lo que se llama, en la práctica, la distribución de Poisson de $\lambda=4*2$**.
```{r}
valores <- round(seq(percentil_min, percentil_max, by=1) ,0)
frecuencias <- fpois(valores, lambda=4*2)
frecuencias_acumuladas <- ppois(valores, lambda=4*2)
frecuencias <- round(frecuencias, cifras)
frecuencias_acumuladas <- round(frecuencias_acumuladas, cifras)
distri_poi <- data.frame(valores, frecuencias, frecuencias_acumuladas)
```

```{r}
curva_poi <- ggplot(data = distri_poi, 
                    aes(x=valores, y=frecuencias)) + 
    geom_line(color = "blue", size=1) + 
    labs(title = "Distribución de Poisson de lambda = 4*2")
curva_poi
```

Finalmente, una muestra "perfecta" de resultados que daría justo las frecuencias teóricas, se puede construir:
    ```{r}
muestra_poi <- rep(distri_poi$valores, 
                   round(distri_poi$frecuencias * my_tamamu, 0))

head(muestra_poi, 200)

ggplot() + 
    geom_histogram(aes(x = muestra_poi, y = ..density..),
                   color = "white", 
                   fill = "orange", 
                   binwidth = 1) +
    labs(title = "Histograma")
```

## Estadística descriptiva de la distribución binomial

Utilizamos nuestra binomial de tamaño 90 y probabilidad 1/6 en los ejemplos:
    
    + pbinom(valor, size=90, prob=1/6)  
+ fbinom(valor, size=90, prob=1/6)  
+ qbinom(valor, size=90, prob=1/6)  
+ distri_bin
+ curva_bin  
+ muestra_bin


#### La media (función mean)

La media es un indicador de la tendencia central, es decir, de cuál es el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo, podríamos decir, de _desviaciones_:
    
    ```{r}
mean(muestra_bin)
```
Se puede demostrar que coincide siempre con: $size \times prob$.

#### La mediana (función median)

La mediana es el valor en el que se iguala o supera por primera vez la frecuencia acumulado de 0.5:
    ```{r}
mean(muestra_bin)
```
Se puede demostrar que coincide siempre la media.

#### Percentiles (función quantile)

El percentil dd es el valor en el que se iguala o supera por primera vez la frecuencia 0.dd:
    ```{r}
quantile(x=muestra_bin, probs=0.05) #percentil 5
quantile(x=muestra_bin, probs=0.95) #percentil 95
quantile(x=muestra_bin, probs=0.50) #percentil 50
```
El percentil 50 es, por definición, la mediana.

#### Sumario (función summary y geometría boxplot)

El sumario es un compendio de 6 indicadores:
    
    + Mínimo (valor más pequeño con algo de frecuencia)  
+ percentil 25, también llamado "primer cuartil"  
+ percentil 50, también llamado "segundo cuartil" o "mediana"  
+ media  
+ percentil 75, también llamado "tercer cuartil"  
+ Máximo (valor más grande con algo de frecuencia)  

```{r}
summary(muestra_bin)
```

El sumario queda muy bien acompañado de un diagrama de cajas. El diagrama de cajas muestra una caja cuya base es el primer cuartil, la tapa es el tercer cuartil, la mediana (que cae dentro de la caja) se marca claramente y se añaden dos líneas perpendiculares a la caja (llamadas "bigotes de la caja") con longitud igual a 1,5 veces la altura de la caja.

También se dibujan aquelos valores que quedan fuera de los bigotes de la caja. Estos valores se consideran atípicos ("outliers").
```{r}
ggplot(data = NULL, aes(x="", y = muestra_bin)) +
    geom_boxplot()
```

#### Histograma (geometría geom_histogram)

El histograma agrupa los valores en intervalos y para cada intervalo levanta una barra _proporcional_ a la frecuencia de los valores que contiene. La anchura del intervalo es calculada automáticamente por R pero se puede sustituir con el parámetro "binwidth". Es habitual acompañarlo con una línea vertical que indica la media:
    
    ```{r}
ggplot() + 
    geom_histogram(aes(x = muestra_bin, y = ..density..),
                   color = "white", 
                   fill = "orange", binwidth = 1) +
    geom_vline(aes(xintercept = mean(muestra_bin)),
               size=1,
               color="black")
```

#### Varianza y desviación típica (funciones var y sd)

La varianza es la media de los cuadrados de las desviaciones con respecto a la media. Como la idea es que la media es "el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo de _desviaciones_", la varianza valora la magnitud de estas _desviaciones_ o, mejor dicho, su cuadrado.

```{r}
var(muestra_bin)
```

Se puede demostrar que coincide siempre con $size \times prob \times (1 - prob)$.

Como la varianza valora el cuadrado de las desviaciones, es más significativa (porque tiene las unidades de medida de la media) su raiz cuadrada, llamada desviación típica:
    ```{r}
sqrt(var(muestra_bin))
sd(muestra_bin)
```

#### Coeficiente de asimetría (función skewness del paquete moments)

El coeficiente de asimetría indica el grado de simetría que tiene el histograma con respecto al eje que supone la media. "Simetría" quiere decir que los valores a izquierda y derecha del eje son prácticamente los mismos y sus frecuencias también. Otro forma de verlo: que las barras del histograma se "reflejan" en el eje de la media.

```{r}
library(moments)
skewness(muestra_bin)
```

El coeficiente de asimetría es positivo así que hay asimetría "hacia la derecha". Esto se ve en el histograma: a la derecha del eje de la media hay más barras. Esto no quiere decir que haya más frecuencia acumulada porque, como la media coincide con la mediana, a ambos lados del eje de la media hay justo un 50% de la frecuencia. Lo que pasa es que hay más valores, más barras. Por eso, son más bajas; de lo contrario, habría más frecuencia acumulada en el lado derecho.

También se suele decir que "la cola derecha es más larga que la izquierda".

Otra "pista" que teníamos en este sentido es que hasta la media hay 14 valores (2, 3, ...15) y desde la media 18 valores (15, 16, ...32).

#### Coeficiente de curtosis (funcion kurtosis del paquete moments)

El coeficiente de curtosis indica si en los extremos del histograma hay una cantidad despreciable de frecuencia acumulada ("colas ligeras"), una cantidad digna de tener en cuenta ("colas pesadas") o una cantidad "normal".

En R, el coeficiente de curtosis gira alrededor del valor "3":
    
    + curtosis menor que 3: colas ligeras  
+ curtosis mayor que 3: colas pesadas

```{r}
library(moments)
kurtosis(muestra_bin)
```

En este caso, la curtosis es prácticamente 3 luego las colas no son ni ligeras ni pesadas.


## Estadística descriptiva de la distribución normal

Utilizamos nuestra normal de media 5 y desviación típica 0.25

+ pnorm(valor, mean=5, sd=0.25)
+ fnorm(valor, mean=5, sd=0.25)
+ qnorm(valor, mean=5, sd=0.25)
+ distri_nor
+ curva_nor 
+ muestra_nor


#### La media (función mean)

La media es un indicador de la tendencia central, es decir, de cuál es el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo, podríamos decir, de _desviaciones_:
    
    ```{r}
mean(muestra_nor)
```
Se puede demostrar que coincide siempre con el parámetro _mean_.

#### La mediana (función median)

La mediana es el valor en el que se iguala o supera por primera vez la frecuencia acumulado de 0.5:
    ```{r}
median(muestra_nor)
```
Se puede demostrar que coincide siempre con la media.

#### Percentiles (función quantile)

El percentil dd es el valor en el que se iguala o supera por primera vez la frecuencia 0.dd:
    ```{r}
quantile(x=muestra_nor, probs=0.05) #percentil 5
quantile(x=muestra_nor, probs=0.95) #percentil 95
quantile(x=muestra_nor, probs=0.50) #percentil 50
```
El percentil 50 es, por definición, la mediana.

#### Sumario (función summary y geometría boxplot)

El sumario es un compendio de 6 indicadores:
    
    + Mínimo (valor más pequeño con algo de frecuencia)  
+ percentil 25, también llamado "primer cuartil"  
+ percentil 50, también llamado "segundo cuartil" o "mediana"  
+ media  
+ percentil 75, también llamado "tercer cuartil"  
+ Máximo (valor más grande con algo de frecuencia)  

```{r}
summary(muestra_nor)
```

El sumario queda muy bien acompañado de un diagrama de cajas. El diagrama de cajas muestra una caja cuya base es el primer cuartil, la tapa es el tercer cuartil, la mediana (que cae dentro de la caja) se marca claramente y se añaden dos líneas perpendiculares a la caja (llamadas "bigotes de la caja") con longitud igual a 1,5 veces la altura de la caja.

También se dibujan aquelos valores que quedan fuera de los bigotes de la caja. Estos valores se consideran atípicos ("outliers").
```{r}
ggplot(data = NULL, aes(x="", y = muestra_nor)) +
    geom_boxplot()
```

#### Histograma (geometría geom_histogram)

El histograma agrupa los valores en intervalos y para cada intervalo levanta una barra _proporcional_ a la frecuencia de los valores que contiene. La anchura del intervalo es calculada automáticamente por R pero se puede sustituir con el parámetro "binwidth". Es habitual acompañarlo con una línea vertical que indica la media:
    
    ```{r}
ggplot() + 
    geom_histogram(aes(x = muestra_nor, y = ..density..),
                   color = "white", 
                   fill = "orange", binwidth = 0.01) +
    geom_vline(aes(xintercept = mean(muestra_nor)),
               size=1,
               color="black")
```

#### Varianza y desviación típica (funciones var y sd)

La varianza es la media de los cuadrados de las desviaciones con respecto a la media. Como la idea es que la media es "el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo de _desviaciones_", la varianza valora la magnitud de estas _desviaciones_ o, mejor dicho, su cuadrado.

```{r}
var(muestra_nor)
```

Se puede demostrar que coincide siempre con el cuadrado del parámetro _sd_.

Como la varianza valora el cuadrado de las desviaciones, es más significativa (porque tiene las unidades de medida de la media) su raiz cuadrada, llamada desviación típica:
    ```{r}
sqrt(var(muestra_nor))
sd(muestra_nor)
```

Se puede demostrar que coincide siempre con el parámetro _sd_.

#### Coeficiente de asimetría (función skewness del paquete moments)

El coeficiente de asimetría indica el grado de simetría que tiene el histograma con respecto al eje que supone la media. "Simetría" quiere decir que los valores a izquierda y derecha del eje son prácticamente los mismos y sus frecuencias también. Otro forma de verlo: que las barras del histograma se "reflejan" en el eje de la media.

```{r}
library(moments)
skewness(muestra_nor)
```

Se puede demostrar que es cero así que la distribución normal es simétrica.

#### Coeficiente de curtosis (funcion kurtosis del paquete moments)

El coeficiente de curtosis indica si en los extremos del histograma hay una cantidad despreciable de frecuencia acumulada ("colas ligeras"), una cantidad digna de tener en cuenta ("colas pesadas") o una cantidad "normal".

En R, el coeficiente de curtosis gira alrededor del valor "3":
    
    + curtosis menor que 3: colas ligeras  
+ curtosis mayor que 3: colas pesadas

```{r}
library(moments)
kurtosis(muestra_nor)
```

Se puede demostrar que es exactamente 3 luego las colas no son ni ligeras ni pesadas.


## Estadística descriptiva de la distribución de Poisson

Utilizamos nuestra poisson de $\lambda = 4*2$:
    
    + ppois(valor, lambda = 4*2)
+ fpois(valor, lambda = 4*2)
+ qpois(valor, lambda = 4*2) 
+ distri_poi  
+ curva_poi  
+ muestra_poi  


#### La media (función mean)

La media es un indicador de la tendencia central, es decir, de cuál es el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo, podríamos decir, de _desviaciones_:
    
    ```{r}
mean(muestra_poi)
```
Se puede demostrar que coincide siempre con el parámetro $\lambda$.

#### La mediana (función median)

La mediana es el valor en el que se iguala o supera por primera vez la frecuencia acumulado de 0.5:
    ```{r}
mean(muestra_poi)
```

#### Percentiles (función quantile)

El percentil dd es el valor en el que se iguala o supera por primera vez la frecuencia 0.dd:
    ```{r}
quantile(x=muestra_poi, probs=0.05) #percentil 5
quantile(x=muestra_poi, probs=0.95) #percentil 95
quantile(x=muestra_poi, probs=0.50) #percentil 50
```
El percentil 50 es, por definición, la mediana.

#### Sumario (función summary y geometría boxplot)

El sumario es un compendio de 6 indicadores:
    
    + Mínimo (valor más pequeño con algo de frecuencia)  
+ percentil 25, también llamado "primer cuartil"  
+ percentil 50, también llamado "segundo cuartil" o "mediana"  
+ media  
+ percentil 75, también llamado "tercer cuartil"  
+ Máximo (valor más grande con algo de frecuencia)  

```{r}
summary(muestra_poi)
```

El sumario queda muy bien acompañado de un diagrama de cajas. El diagrama de cajas muestra una caja cuya base es el primer cuartil, la tapa es el tercer cuartil, la mediana (que cae dentro de la caja) se marca claramente y se añaden dos líneas perpendiculares a la caja (llamadas "bigotes de la caja") con longitud igual a 1,5 veces la altura de la caja.

También se dibujan aquelos valores que quedan fuera de los bigotes de la caja. Estos valores se consideran atípicos ("outliers").
```{r}
ggplot(data = NULL, aes(x="", y = muestra_poi)) +
    geom_boxplot()
```

#### Histograma (geometría geom_histogram)

El histograma agrupa los valores en intervalos y para cada intervalo levanta una barra _proporcional_ a la frecuencia de los valores que contiene. La anchura del intervalo es calculada automáticamente por R pero se puede sustituir con el parámetro "binwidth". Es habitual acompañarlo con una línea vertical que indica la media:
    
    ```{r}
ggplot() + 
    geom_histogram(aes(x = muestra_poi, y = ..density..),
                   color = "white", 
                   fill = "orange", binwidth = 1) +
    geom_vline(aes(xintercept = mean(muestra_poi)),
               size=1,
               color="black")
```

#### Varianza y desviación típica (funciones var y sd)

La varianza es la media de los cuadrados de las desviaciones con respecto a la media. Como la idea es que la media es "el valor más _céntrico_ de la distribución, del cual emanan los demás valores a modo de _desviaciones_", la varianza valora la magnitud de estas _desviaciones_ o, mejor dicho, su cuadrado.

```{r}
var(muestra_poi)
```

Se puede demostrar que coincide siempre con el parámetro $\lambda$.

Como la varianza valora el cuadrado de las desviaciones, es más significativa (porque tiene las unidades de medida de la media) su raiz cuadrada, llamada desviación típica:
    ```{r}
sqrt(var(muestra_poi))
sd(muestra_poi)
```
Se puede demostrar que coincide siempre con $\sqrt{\lambda}$.

#### Coeficiente de asimetría (función skewness del paquete moments)

El coeficiente de asimetría indica el grado de simetría que tiene el histograma con respecto al eje que supone la media. "Simetría" quiere decir que los valores a izquierda y derecha del eje son prácticamente los mismos y sus frecuencias también. Otro forma de verlo: que las barras del histograma se "reflejan" en el eje de la media.

```{r}
library(moments)
skewness(muestra_poi)
```

El coeficiente de asimetría es positivo y bastante grande así que hay mucha asimetría "hacia la derecha". Se puede demostrar que coincide siempre con $1/\sqrt{\lambda}$.

Esta asimetría se ve en el histograma: a la derecha del eje de la media hay más barras. También se suele decir que "la cola derecha es más larga que la izquierda".

Otra "pista" que teníamos en este sentido es que hasta la media hay 9 valores (0, 1, ...8) y desde la media 16 valores (8, 9, ...23).

#### Coeficiente de curtosis (funcion kurtosis del paquete moments)

El coeficiente de curtosis indica si en los extremos del histograma hay una cantidad despreciable de frecuencia acumulada ("colas ligeras"), una cantidad digna de tener en cuenta ("colas pesadas") o una cantidad "normal".

En R, el coeficiente de curtosis gira alrededor del valor "3":
    
    + curtosis menor que 3: colas ligeras  
+ curtosis mayor que 3: colas pesadas

```{r}
library(moments)
kurtosis(muestra_poi)
```

En este caso, la curtosis es un poco mayor que 3, luego las colas son algo pesadas.

Se puede demostrar que coincide siempre con $3 + 1/\lambda$.
